{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb6375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student Improvement Prediction Model (Operational Notebook)\n",
    "# File: student improvement prediction model.ipynb\n",
    "# Purpose: Predict whether a student will improve given a finalized task list\n",
    "# and estimate how much and how soon improvement will occur across timelines.\n",
    "\n",
    "\"\"\"\n",
    "USAGE NOTES (Operational-ready):\n",
    "- This notebook expects the following inputs to be provided (from the ML Student Improvement Model\n",
    "  or your backend) before running the prediction cells:\n",
    "\n",
    "  1) student_history: pandas.DataFrame\n",
    "     - columns: ['student_id','date','subject','score','task_type','time_spent_minutes','completed']\n",
    "     - date must be a datetime\n",
    "\n",
    "  2) final_suggestions: dict or pandas.DataFrame\n",
    "     - If dict per student: {\n",
    "         student_id: {\n",
    "           'tasks': [{ 'task': str, 'xp': int, 'subject': str, 'estimated_minutes': int } , ...],\n",
    "           'summary': str\n",
    "         }, ... }\n",
    "     - Or a DataFrame with columns: ['student_id','task','xp','subject','estimated_minutes']\n",
    "\n",
    "  3) student_attributes: pandas.DataFrame (hardwork/determination/focus/creativity/discipline)\n",
    "     - columns: ['student_id','hardwork','determination','focus','creativity','discipline']\n",
    "     - values in range [0,1] or [0,100] (the notebook normalizes)\n",
    "\n",
    "- The notebook produces:\n",
    "  - per-student, per-subject predictions for probability of improvement (classification)\n",
    "  - predicted mark increase (regression)\n",
    "  - predicted time horizons for improvement across multiple timelines (1w,3w,1m,2m,6m,1y)\n",
    "  - justification/analysis by comparing predictions to historical improvement\n",
    "\n",
    "- This notebook is intentionally implementation-ready but DOES NOT include any hard-coded sample data.\n",
    "  Provide your real dataframes into the environment and run the cells.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 0. Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --------------------------- Helper functions ---------------------------\n",
    "\n",
    "def normalize_attributes(df, cols):\n",
    "    df2 = df.copy()\n",
    "    for c in cols:\n",
    "        # scale to 0-1 if not already\n",
    "        if df2[c].max() > 1:\n",
    "            df2[c] = (df2[c] - df2[c].min()) / (df2[c].max() - df2[c].min() + 1e-9)\n",
    "        else:\n",
    "            df2[c] = df2[c].clip(0,1)\n",
    "    return df2\n",
    "\n",
    "\n",
    "def aggregate_student_history(history_df):\n",
    "    \"\"\"\n",
    "    Returns aggregated features per student and subject\n",
    "    Features include: mean_score, last_score, improvement_rate, avg_time_spent, completion_rate, sessions\n",
    "    \"\"\"\n",
    "    h = history_df.copy()\n",
    "    # ensure date\n",
    "    h['date'] = pd.to_datetime(h['date'])\n",
    "\n",
    "    agg = h.groupby(['student_id','subject']).agg(\n",
    "        mean_score = ('score','mean'),\n",
    "        last_score = ('score', 'last'),\n",
    "        first_score = ('score','first'),\n",
    "        improvement_total = (lambda x: x.iloc[-1] - x.iloc[0], 'score'),\n",
    "        sessions = ('score','count'),\n",
    "        avg_time_spent = ('time_spent_minutes','mean'),\n",
    "        completion_rate = ('completed','mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # improvement rate per session\n",
    "    agg['improvement_per_session'] = (agg['last_score'] - agg['first_score']) / (agg['sessions'] + 1e-9)\n",
    "    return agg\n",
    "\n",
    "\n",
    "def prepare_features(agg_df, final_suggestions_df, attributes_df):\n",
    "    \"\"\"\n",
    "    Merge aggregated history, suggestions and attributes into model features.\n",
    "    final_suggestions_df expected columns: ['student_id','task','xp','subject','estimated_minutes']\n",
    "    We will aggregate suggestions per student/subject: total_xp, count_tasks, est_minutes\n",
    "    \"\"\"\n",
    "    sug = final_suggestions_df.copy()\n",
    "    sug_agg = sug.groupby(['student_id','subject']).agg(\n",
    "        total_xp = ('xp','sum'),\n",
    "        n_tasks = ('task','count'),\n",
    "        est_minutes = ('estimated_minutes','sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # merge\n",
    "    m = agg_df.merge(sug_agg, how='left', on=['student_id','subject'])\n",
    "    m = m.merge(attributes_df, how='left', on='student_id')\n",
    "\n",
    "    # fillna\n",
    "    m['total_xp'] = m['total_xp'].fillna(0)\n",
    "    m['n_tasks'] = m['n_tasks'].fillna(0)\n",
    "    m['est_minutes'] = m['est_minutes'].fillna(0)\n",
    "\n",
    "    # normalize attributes\n",
    "    attr_cols = ['hardwork','determination','focus','creativity','discipline']\n",
    "    m = normalize_attributes(m, [c for c in attr_cols if c in m.columns])\n",
    "\n",
    "    return m\n",
    "\n",
    "# --------------------------- Prediction models ---------------------------\n",
    "\n",
    "class StudentImprovementPredictor:\n",
    "    \"\"\"\n",
    "    - classifier: predict probability that the student WILL improve within a given timeline\n",
    "    - regressor: predict the expected increase in marks\n",
    "    We train simple RandomForest models on historical aggregated data, but in operation,\n",
    "    user may supply pre-trained weights or we can re-fit on the available historical data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "        self.reg = RandomForestRegressor(n_estimators=150, random_state=42)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_cols = None\n",
    "\n",
    "    def fit(self, features_df):\n",
    "        \"\"\"\n",
    "        features_df must contain:\n",
    "          - features (numeric)\n",
    "          - target columns: 'will_improve' (0/1), 'mark_increase' (float)\n",
    "        \"\"\"\n",
    "        df = features_df.copy()\n",
    "        # Drop rows with missing target\n",
    "        df = df.dropna(subset=['will_improve','mark_increase'])\n",
    "\n",
    "        X = df.drop(columns=['student_id','subject','will_improve','mark_increase'])\n",
    "        y_clf = df['will_improve'].astype(int)\n",
    "        y_reg = df['mark_increase'].astype(float)\n",
    "\n",
    "        self.feature_cols = X.columns.tolist()\n",
    "        Xs = self.scaler.fit_transform(X)\n",
    "        self.clf.fit(Xs, y_clf)\n",
    "        self.reg.fit(Xs, y_reg)\n",
    "        return self\n",
    "\n",
    "    def predict(self, features_df):\n",
    "        df = features_df.copy()\n",
    "        X = df[self.feature_cols].fillna(0)\n",
    "        Xs = self.scaler.transform(X)\n",
    "        prob = self.clf.predict_proba(Xs)[:,1]\n",
    "        mark_inc = self.reg.predict(Xs)\n",
    "        out = df[['student_id','subject']].copy()\n",
    "        out['improve_prob'] = prob\n",
    "        out['predicted_mark_increase'] = mark_inc\n",
    "        return out\n",
    "\n",
    "# --------------------------- Time-horizon forecasting ---------------------------\n",
    "\n",
    "def horizon_predictions(base_features_df, predictor, timelines=['1w','3w','1m','2m','6m','1y']):\n",
    "    \"\"\"\n",
    "    Produce predictions across different timelines.\n",
    "    Simple operational approach: for each horizon we slightly scale expected effect of tasks and attributes.\n",
    "    A more advanced approach would train timeline-specific models.\n",
    "    \"\"\"\n",
    "    multipliers = {\n",
    "        '1w': 0.15,\n",
    "        '3w': 0.35,\n",
    "        '1m': 0.5,\n",
    "        '2m': 0.7,\n",
    "        '6m': 0.95,\n",
    "        '1y': 1.0\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for t in timelines:\n",
    "        df = base_features_df.copy()\n",
    "        # scale xp and est_minutes effect for horizon\n",
    "        if 'total_xp' in df.columns:\n",
    "            df['total_xp_scaled'] = df['total_xp'] * multipliers[t]\n",
    "        if 'est_minutes' in df.columns:\n",
    "            df['est_minutes_scaled'] = df['est_minutes'] * multipliers[t]\n",
    "        # create a feature vector matching predictor.feature_cols\n",
    "        # fallback: if new scaled columns not used in training, ensure presence\n",
    "        for col in predictor.feature_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0\n",
    "        # if scaled columns present but original also present, prefer scaled values for prediction\n",
    "        if 'total_xp_scaled' in df.columns and 'total_xp' in df.columns:\n",
    "            df['total_xp'] = df['total_xp_scaled']\n",
    "        if 'est_minutes_scaled' in df.columns and 'est_minutes' in df.columns:\n",
    "            df['est_minutes'] = df['est_minutes_scaled']\n",
    "\n",
    "        pred = predictor.predict(df[predictor.feature_cols + ['student_id','subject']])\n",
    "        pred['timeline'] = t\n",
    "        results.append(pred)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "# --------------------------- Evaluation & Justification ---------------------------\n",
    "\n",
    "def evaluate_predictions(pred_df, actual_df):\n",
    "    \"\"\"\n",
    "    Compare predicted improvement & mark increase to actual changes in actual_df.\n",
    "    actual_df: historical aggregated df containing 'student_id','subject','future_mark_increase'\n",
    "    Returns summary metrics and a small justification text per student-subject.\n",
    "    \"\"\"\n",
    "    merged = pred_df.merge(actual_df, on=['student_id','subject'], how='left')\n",
    "    # compute errors\n",
    "    mae = mean_absolute_error(merged['future_mark_increase'].fillna(0), merged['predicted_mark_increase'].fillna(0))\n",
    "    r2 = r2_score(merged['future_mark_increase'].fillna(0), merged['predicted_mark_increase'].fillna(0))\n",
    "\n",
    "    # reason: for each row explain whether prediction was optimistic/pessimistic and why\n",
    "    reasons = []\n",
    "    for _, row in merged.iterrows():\n",
    "        act = row.get('future_mark_increase', None)\n",
    "        pred = row['predicted_mark_increase']\n",
    "        if pd.isna(act):\n",
    "            reasons.append('No ground truth available for this student-subject; cannot fully validate.')\n",
    "            continue\n",
    "        diff = pred - act\n",
    "        if abs(diff) < 2:\n",
    "            reasons.append('Prediction close to actual (within 2 marks).')\n",
    "        elif diff > 2:\n",
    "            reasons.append('Prediction optimistic — predicted higher improvement than realized. Check attribute overestimation or low completion_rate.')\n",
    "        else:\n",
    "            reasons.append('Prediction conservative — model underpredicted improvement; consider unusual high effort in follow-up data.')\n",
    "\n",
    "    merged['justification'] = reasons\n",
    "    summary = {'MAE_mark_increase': mae, 'R2': r2}\n",
    "    return summary, merged\n",
    "\n",
    "# --------------------------- Operational Entry-Point ---------------------------\n",
    "\n",
    "def run_prediction_pipeline(student_history, final_suggestions, student_attributes, timelines=['1w','3w','1m','2m','6m','1y'], retrain=True):\n",
    "    \"\"\"\n",
    "    1) Aggregate history\n",
    "    2) Prepare features by merging suggestions and attributes\n",
    "    3) If retrain==True and enough historical rows exist, fit models using historical targets\n",
    "       (For historical targets, the system expects these columns to be available or calculated externally.)\n",
    "    4) Produce timeline predictions\n",
    "    5) Return predictions dataframe\n",
    "    \"\"\"\n",
    "    # sanity checks\n",
    "    assert 'student_id' in student_history.columns, 'student_history must include student_id'\n",
    "    assert isinstance(final_suggestions, (pd.DataFrame, dict)), 'final_suggestions must be DataFrame or dict'\n",
    "    assert 'student_id' in student_attributes.columns, 'student_attributes must include student_id'\n",
    "\n",
    "    # 1. Aggregate history\n",
    "    agg = aggregate_student_history(student_history)\n",
    "\n",
    "    # 2. Normalize suggestions into a DataFrame if dict supplied\n",
    "    if isinstance(final_suggestions, dict):\n",
    "        rows = []\n",
    "        for sid, payload in final_suggestions.items():\n",
    "            for t in payload.get('tasks', []):\n",
    "                rows.append({'student_id': sid, 'task': t.get('task'), 'xp': t.get('xp',0), 'subject': t.get('subject'), 'estimated_minutes': t.get('estimated_minutes',0)})\n",
    "        final_suggestions_df = pd.DataFrame(rows)\n",
    "    else:\n",
    "        final_suggestions_df = final_suggestions.copy()\n",
    "\n",
    "    # 3. Prepare feature matrix\n",
    "    features = prepare_features(agg, final_suggestions_df, student_attributes)\n",
    "\n",
    "    # For training, we expect two target columns: will_improve (0/1) and mark_increase (float)\n",
    "    # If these aren't present, we will not train and instead require a pre-trained predictor provided by user.\n",
    "    predictor = StudentImprovementPredictor()\n",
    "    if retrain and 'will_improve' in features.columns and 'mark_increase' in features.columns and len(features) > 20:\n",
    "        predictor.fit(features)\n",
    "    else:\n",
    "        # operational default: fit on synthetic target derived from history if explicit target absent\n",
    "        # create a proxy target: mark_increase = improvement_per_session * estimated sessions remaining\n",
    "        feats = features.copy()\n",
    "        # estimate remaining sessions roughly as n_tasks (if present) or 4\n",
    "        feats['est_sessions_remain'] = feats.get('n_tasks', 4).fillna(4)\n",
    "        feats['mark_increase'] = feats['improvement_per_session'] * feats['est_sessions_remain']\n",
    "        feats['will_improve'] = (feats['mark_increase'] > 0).astype(int)\n",
    "        predictor.fit(feats)\n",
    "\n",
    "    # 4. produce horizon predictions\n",
    "    preds = horizon_predictions(features, predictor, timelines=timelines)\n",
    "\n",
    "    # 5. Format subject-wise and mark-wise predictions\n",
    "    preds_subject_wise = preds.copy()\n",
    "    # Convert probabilities to labels for convenience\n",
    "    preds_subject_wise['will_improve_label'] = (preds_subject_wise['improve_prob'] >= 0.5).astype(int)\n",
    "\n",
    "    return preds_subject_wise\n",
    "\n",
    "# --------------------------- Example of call (do NOT run without providing data) ---------------------------\n",
    "# preds = run_prediction_pipeline(student_history, final_suggestions, student_attributes)\n",
    "# print(preds.head())\n",
    "\n",
    "# --------------------------- Save/Export helpers ---------------------------\n",
    "\n",
    "def export_predictions_to_csv(predictions_df, path):\n",
    "    predictions_df.to_csv(path, index=False)\n",
    "    return path\n",
    "\n",
    "\n",
    "# --------------------------- End of Notebook ---------------------------\n",
    "# Provide this notebook with your operational dataframes and call run_prediction_pipeline(...) to get predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
